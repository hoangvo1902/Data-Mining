{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSYvP0n8RjYH"
   },
   "source": [
    "# Lab02: Frequent itemset mining\n",
    "\n",
    "- Student ID: 20127028\n",
    "- Student name: Vo Van Hoang\n",
    "\n",
    "**How to do your homework**\n",
    "\n",
    "\n",
    "You will work directly on this notebook; the word `TODO` indicate the parts you need to do.\n",
    "\n",
    "You can discuss ideas with classmates as well as finding information from the internet, book, etc...; but *this homework must be yours*.\n",
    "\n",
    "**How to submit your homework**\n",
    "\n",
    "Before submitting, rerun the notebook (`Kernel` ->` Restart & Run All`).\n",
    "\n",
    "Then create a folder named `ID` (for example, if your ID is 1234567, then name the folder `1234567`) Copy file notebook to this folder, compress and submit it on moodle.\n",
    "\n",
    "**Contents:**\n",
    "\n",
    "- Frequent itemset mining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXZ5gCVaRjYa"
   },
   "source": [
    "# 1. Preliminaries\n",
    "## This is how it all started ...\n",
    "- Rakesh Agrawal, Tomasz Imielinski, Arun N. Swami: Mining Association Rules between Sets of Items in Large Databases. SIGMOD Conference 1993: 207-216\n",
    "- Rakesh Agrawal, Ramakrishnan Srikant: Fast Algorithms for Mining Association Rules in Large Databases. VLDB 1994: 487-499\n",
    "\n",
    "**These two papers are credited with the birth of Data Mining**\n",
    "## Frequent itemset mining (FIM)\n",
    "\n",
    "Find combinations of items (itemsets) that occur frequently.\n",
    "## Applications\n",
    "- Items = products, transactions = sets of products someone bought in one trip to the store.\n",
    "$\\Rightarrow$ items people frequently buy together.\n",
    "    + Example: if people usually buy bread and coffee together, we run a sale of bread to attract people attention and raise price of coffee.\n",
    "- Items = webpages, transactions = words. Unusual words appearing together in a large number of documents, e.g., “Brad” and “Angelina,” may indicate an interesting relationship.\n",
    "- Transactions = Sentences, Items = Documents containing those sentences. Items that appear together too often could represent plagiarism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8vAJ8A2RjYi"
   },
   "source": [
    "## Transactional Database\n",
    "A transactional database $D$ consists of $N$ transactions: $D=\\left\\{T_1,T_2,...,T_N\\right\\}$. A transaction $T_n \\in D (1 \\le n \\le N)$ contains one or more items and that $I= \\left\\{ i_1,i_2,…,i_M \\right\\}$ is the set of distinct items in $D$, $T_n \\subset I$. Commonly, a transactional database is represented by a flat file instead of a database system: items are non-negative integers, each row represents a transaction, items in a transaction separated by space.\n",
    "\n",
    "Example: \n",
    "\n",
    "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 \n",
    "\n",
    "30 31 32 \n",
    "\n",
    "33 34 35 \n",
    "\n",
    "36 37 38 39 40 41 42 43 44 45 46 \n",
    "\n",
    "38 39 47 48 \n",
    "\n",
    "38 39 48 49 50 51 52 53 54 55 56 57 58 \n",
    "\n",
    "32 41 59 60 61 62 \n",
    "\n",
    "3 39 48 \n",
    "\n",
    "63 64 65 66 67 68 \n",
    "\n",
    "\n",
    "\n",
    "# Definition\n",
    "\n",
    "- Itemset: A collection of one or more items.\n",
    "    + Example: {1 4 5}\n",
    "- **k-itemset**: An itemset that contains k items.\n",
    "- Support: Frequency of occurrence of an itemset.\n",
    "    + Example: From the example above, item 3 appear in 2 transactions so its support is 2.\n",
    "- Frequent itemset: An itemset whose support is greater than or equal to a `minsup` threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdykKxr6RjY-"
   },
   "source": [
    "# The Apriori Principle\n",
    "- If an itemset is frequent, then all of its subsets must also be frequent.\n",
    "- If an itemset is not frequent, then all of its supersets cannot be frequent.\n",
    "- The support of an itemset never exceeds the support of its subsets.\n",
    "$$ \\forall{X,Y}: (X \\subseteq Y) \\Rightarrow s(X)\\ge s(Y)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvfMR7-CRjZB"
   },
   "source": [
    "# 2. Implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9gZh4DORjZD"
   },
   "source": [
    "## The Apriori algorithm\n",
    "Suppose:\n",
    "\n",
    "$C_k$ candidate itemsets of size k.\n",
    "\n",
    "$L_k$ frequent itemsets of size k.\n",
    "\n",
    "The level-wise approach of Apriori algorithm can be descibed as follow:\n",
    "1. k=1, $C_k$ = all items.\n",
    "2. While $C_k$ not empty:\n",
    "    3. Scan the database to find which itemsets in $C_k$ are frequent and put them into $L_k$.\n",
    "    4. Use $L_k$ to generate a collection of candidate itemsets $C_{k+1}$ of size k+1.\n",
    "    5. k=k+1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qF9xHOBLRjZJ"
   },
   "source": [
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "id": "7F0lUOSuRjZN"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OogwdcLRjZf"
   },
   "source": [
    "### Read data\n",
    "First we have to read data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "id": "U2bsGrTERjZg"
   },
   "outputs": [],
   "source": [
    "def readData(path):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    --------------------------\n",
    "        path: path of database D.         \n",
    "    --------------------------\n",
    "    Returns\n",
    "        data: a dictionary for representing database D\n",
    "                 - keys: transaction tids\n",
    "                 - values: itemsets.\n",
    "        s: support of distict items in D.\n",
    "    \"\"\"\n",
    "    data={}\n",
    "    s=defaultdict(lambda: 0) # Initialize a dictionary for storing support of items in I.  \n",
    "    with open(path,'rt') as f:\n",
    "        tid=1;\n",
    "        for line in f:\n",
    "            itemset=set(map(int,line.split())) # a python set is a native way for storing an itemset.\n",
    "            for item in itemset:  \n",
    "                s[item]+=1     #Why don't we compute support of items while reading data?\n",
    "            data[tid]= itemset\n",
    "            tid+=1\n",
    "    \n",
    "    return data, s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSTC78WURjZu"
   },
   "source": [
    "### Tree Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGAkmuXtRjZw"
   },
   "source": [
    "**I gave you pseudo code of Apriori algorithm above but we implement Tree Projection. Tell me the differences of two algorithms.**\n",
    "\n",
    "\n",
    "**TODO:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "id": "BVRT5BnWRjZz"
   },
   "outputs": [],
   "source": [
    "def joinset(a, b):\n",
    "    '''\n",
    "    Parameters\n",
    "    -------------------\n",
    "        2 itemsets a and b (of course they are at same branch in search space)\n",
    "    -------------------\n",
    "    return\n",
    "        ret: itemset generated by joining a and b\n",
    "    '''\n",
    "    # TODO (hint: this function will be called in generateSearchSpace method.):\n",
    "    ret = list(set(a + b))\n",
    "    ret = sorted(ret)  \n",
    "    return ret\n",
    "\n",
    "class TP:\n",
    "    def __init__(self, data=None, s=None, minSup=None):\n",
    "        self.data = data\n",
    "        self.s = {}\n",
    "        for key, support in sorted(s.items(), key=lambda item: item[1]):\n",
    "            self.s[key] = support\n",
    "        # TODO: why should we do this, answer it at the markdown below?\n",
    "        self.minSup = minSup\n",
    "        self.L = {}  # Store frequent itemsets mined from database\n",
    "        self.runAlgorithm()\n",
    "        \n",
    "    def initialize(self):\n",
    "        \"\"\"\n",
    "        Initialize search space at first step\n",
    "        --------------------------------------\n",
    "        We represent our search space in a tree structure\n",
    "        \"\"\"\n",
    "        tree = {}\n",
    "        search_space = {}\n",
    "        for item, support in self.s.items():\n",
    "            search_space[item] = {}\n",
    "            search_space[item]['itemset'] = [item]\n",
    "            ''' \n",
    "            python set does not remain elements order\n",
    "            so we use a list to extend it easily when create new itemset \n",
    "            but why we store itemset in data by a python set???? '''\n",
    "            # TODO: study about python set and its advantages,\n",
    "            # answer at the markdown below.\n",
    "            search_space[item]['pruned'] = False\n",
    "            # TODO:\n",
    "            # After finish implementing the algorithm tell me why should you use this\n",
    "            # instead of delete item directly from search_space and tree.\n",
    "            search_space[item]['support'] = support\n",
    "            tree[item] = {}\n",
    "            '''\n",
    "            Why should i store an additional tree (here it called tree)? \n",
    "            Answer: This really help in next steps.\n",
    "            Remember that there is always a big gap from theory to practicality\n",
    "            and implementing this algorithm in python is not as simple as you think.\n",
    "            '''\n",
    "        return tree, search_space\n",
    "    \n",
    "    def computeItemsetSupport(self, itemset):\n",
    "        '''Return support of itemset'''\n",
    "        # TODO (hint: this is why i use python set in data)\n",
    "        support = 0\n",
    "        if isinstance(itemset, int):\n",
    "            itemset = {itemset}\n",
    "        else:\n",
    "            itemset = set(itemset)\n",
    "        for transaction in self.data.values():\n",
    "            if itemset.issubset(transaction):\n",
    "                support += 1\n",
    "        return support\n",
    "    \n",
    "    def get_sub_tree(self, k, tree, search_space, itter_node):\n",
    "        if k == 0:\n",
    "            return search_space[itter_node]['support']\n",
    "        subtree = search_space[itter_node]\n",
    "        for node in subtree.keys():\n",
    "            k-=1\n",
    "            self.get_sub_tree(k,tree,search_space,node)\n",
    "\n",
    "    def prune(self, k, tree, search_space):\n",
    "        '''\n",
    "        In this method we will find out which itemset in current search space is frequent\n",
    "        itemset then add it to L[k]. In addition, we prune those are not frequent itemsets.\n",
    "        '''\n",
    "        if self.L.get(k) is None: self.L[k] = []\n",
    "        # TODO\n",
    "        itemset_support = []\n",
    "        for it_set in search_space.keys():\n",
    "            support = self.computeItemsetSupport(it_set)\n",
    "            itemset_support.append(support)\n",
    "        for itemset, properties in search_space.items():  \n",
    "            if properties['pruned']:\n",
    "                continue\n",
    "            support = self.computeItemsetSupport(search_space[itemset]['itemset'])\n",
    "            if support < self.minSup:\n",
    "                search_space[itemset]['pruned'] = True\n",
    "            else:\n",
    "                frequent_itemset = list(properties['itemset'])\n",
    "                self.L[k].append(frequent_itemset)\n",
    "        \n",
    "    def generateSearchSpace(self, k, tree, search_space):\n",
    "        '''\n",
    "        Generate search space for exploring k+1 itemset. (Recursive function)\n",
    "        '''\n",
    "        items = list(tree.keys())\n",
    "        ''' print search_space.keys() you will understand  \n",
    "         why we need an additional tree, '''\n",
    "        l = len(items)\n",
    "        self.prune(k, tree, search_space)\n",
    "        if l == 0: return  # Stop condition\n",
    "        for i in range(l - 1):\n",
    "            sub_search_space = {}\n",
    "            sub_tree = {}\n",
    "            a = items[i]\n",
    "            if search_space[a]['pruned']: continue\n",
    "            for j in range(i + 1, l):\n",
    "                b = items[j]\n",
    "                search_space[a][b] = {}\n",
    "                tree[a][b] = {}\n",
    "                # You really need to understand what am i doing here before doing work below.\n",
    "                # (Hint: draw tree and search space to draft).\n",
    "                # TODO:\n",
    "                # First create newset using join set               \n",
    "                newset = tuple(sorted(joinset(list(search_space[a]['itemset']), list(search_space[b]['itemset']))))               \n",
    "                # Second add newset to search_space\n",
    "                if newset is not None:\n",
    "                    newset_support = self.computeItemsetSupport(newset)\n",
    "                    newset = tuple(newset)   \n",
    "                    if newset_support >= self.minSup:\n",
    "                        search_space[a][b]['itemset'] = list(newset)\n",
    "                        search_space[a][b]['pruned'] = False\n",
    "                        search_space[a][b]['support'] = newset_support\n",
    "                        search_space[newset] = {'itemset': newset, 'pruned': False, 'support': newset_support}\n",
    "                        sub_search_space[newset] = {'itemset': newset, 'pruned': False, 'support': newset_support}\n",
    "                        sub_tree[newset] = {}                \n",
    "            #  Generate search_space for k+1-itemset\n",
    "            self.generateSearchSpace(k + 1, sub_tree, sub_search_space)\n",
    "            \n",
    "    def runAlgorithm(self):\n",
    "        tree, search_space = self.initialize()  # generate search space for 1-itemset\n",
    "        self.generateSearchSpace(1, tree, search_space)\n",
    "        \n",
    "    def miningResults(self):\n",
    "        return self.L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tMTpwxLRjZ-"
   },
   "source": [
    "Ok, let's test on a typical dataset `chess`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "id": "gLygYqiYRjZ-"
   },
   "outputs": [],
   "source": [
    "data, s= readData('chess.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PnxbU77YRjaF",
    "outputId": "c3b158be-6b46-4a3c-9b71-6a92d3d31ded"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [[48], [56], [66], [34], [62], [7], [36], [60], [40], [29], [52], [58]], 2: [[48, 52], [48, 58], [29, 56], [52, 56], [56, 58], [60, 66], [29, 66], [52, 66], [58, 66], [34, 40], [29, 34], [34, 52], [34, 58], [60, 62], [40, 62], [29, 62], [52, 62], [58, 62], [7, 60], [7, 40], [7, 29], [7, 52], [7, 58], [36, 60], [36, 40], [29, 36], [36, 52], [36, 58], [40, 60], [29, 60], [52, 60], [58, 60], [29, 40], [40, 52], [40, 58], [29, 52], [29, 58], [52, 58]], 3: [[48, 52, 58], [29, 52, 56], [29, 56, 58], [52, 56, 58], [29, 60, 66], [52, 60, 66], [58, 60, 66], [29, 52, 66], [29, 58, 66], [52, 58, 66], [29, 34, 40], [34, 40, 52], [34, 40, 58], [29, 34, 52], [29, 34, 58], [34, 52, 58], [29, 60, 62], [52, 60, 62], [58, 60, 62], [29, 40, 62], [40, 52, 62], [40, 58, 62], [29, 52, 62], [29, 58, 62], [52, 58, 62], [7, 40, 60], [7, 29, 60], [7, 52, 60], [7, 58, 60], [7, 29, 40], [7, 40, 52], [7, 40, 58], [7, 29, 52], [7, 29, 58], [7, 52, 58], [36, 40, 60], [29, 36, 60], [36, 52, 60], [36, 58, 60], [29, 36, 40], [36, 40, 52], [36, 40, 58], [29, 36, 52], [29, 36, 58], [36, 52, 58], [29, 40, 60], [40, 52, 60], [40, 58, 60], [29, 52, 60], [29, 58, 60], [52, 58, 60], [29, 40, 52], [29, 40, 58], [40, 52, 58], [29, 52, 58]], 4: [[29, 52, 56, 58], [29, 52, 60, 66], [29, 58, 60, 66], [52, 58, 60, 66], [29, 52, 58, 66], [29, 34, 40, 52], [29, 34, 40, 58], [34, 40, 52, 58], [29, 34, 52, 58], [29, 58, 60, 62], [52, 58, 60, 62], [29, 40, 52, 62], [29, 40, 58, 62], [40, 52, 58, 62], [29, 52, 58, 62], [7, 40, 58, 60], [7, 29, 52, 60], [7, 29, 58, 60], [7, 52, 58, 60], [7, 29, 40, 52], [7, 29, 40, 58], [7, 40, 52, 58], [7, 29, 52, 58], [29, 36, 40, 60], [36, 40, 52, 60], [36, 40, 58, 60], [29, 36, 52, 60], [29, 36, 58, 60], [36, 52, 58, 60], [29, 36, 40, 52], [29, 36, 40, 58], [36, 40, 52, 58], [29, 36, 52, 58], [29, 40, 52, 60], [29, 40, 58, 60], [40, 52, 58, 60], [29, 52, 58, 60], [29, 40, 52, 58]], 5: [[29, 52, 58, 60, 66], [29, 34, 40, 52, 58], [29, 40, 52, 58, 62], [7, 29, 52, 58, 60], [7, 29, 40, 52, 58], [29, 36, 40, 52, 60], [29, 36, 40, 58, 60], [36, 40, 52, 58, 60], [29, 36, 52, 58, 60], [29, 36, 40, 52, 58], [29, 40, 52, 58, 60]], 6: [[29, 36, 40, 52, 58, 60]]}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "a=TP(data=data,s=s, minSup=3000)\n",
    "print(a.miningResults())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mp0RFbw-RjaU"
   },
   "source": [
    "### Answer questions here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Why don't we compute support of items while reading data?**\n",
    "\n",
    "- This method requires us to store all the transactions in memory which can become very out of memory or time-consuming as the size of the data file rises. Furthermore, we won't count item support while reading the data because we need to convert the raw data from string to int and then implement item support on transactions of data file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Why should we do sort?**\n",
    "- Because it enables us to identify all of the individual items that appear in the data, count the frequency of occurrence of each item, and group all occurrences of the same item together, we can count each item more quickly and efficiently. Furthermore, data sorting aids in the generation of larger item sets from smaller item sets, which is required in order to locate all frequent item sets. A good way to narrow down the search space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Study about python set and its advantages?**\n",
    "\n",
    "- To begin, any duplicates are automatically removed. Second, find the element that is shared by both sets, then remove the element from this set that is also shared by another set because it performs set operations. Third, Set Data contains only unique elements, making set operations like union, intersection be simpler. Fourth, tuples store their elements in hash tables, which allows for quick lookups. As a result, the data format in the FIM algorithm is set to help them perform efficiently in all aspects of time to realize capacity and memory usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. After finishing implementing the algorithm tell me why should you use this instead of deleting item directly from search_space and tree.**\n",
    "- Using the variable pruned instead of directly deleting from search space and tree can assist us in keeping track of the items pruned during the tree traversal. This can be useful in certain situations, such as when analyzing the algorithm's performance or extracting information from the pruned items.\n",
    "\n",
    "\n",
    "- Furthermore, removing an item directly can be computationally expensive because it necessitates a complete scan of the search space and tree. In contrast, the algorithm only needs to scan a subset of the search space and tree, saving significant computation time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Apriori algorithm and Tree Projection, tell me the differences of two algorithms.**\n",
    "- Although these 2 algorithms have many similarities: to begin, both techniques are used to extract frequent itemets from a transaction database. Second, both techniques employ the concept of support to identify frequently occurring itemsets. Furthermore, both techniques involve the creation of a data structure that stores information about frequently occurring itemsets and can be used to efficiently generate rules. Furthermore, both techniques include a pruning step to eliminate infrequent itemets and reduce the search space. Finally, both techniques can be used to generate association rules from frequently used itemsets.\n",
    "\n",
    "\n",
    "- Besides that, they also have some differences: First of all, The Tree Projection method uses less memory than the Apriori algorithm because it only keeps track of the frequently occurring items in the tree structure, whereas the Apriori algorithm must keep all candidate itemets in memory. Furthermore, because it can handle a broader range of data formats, the Apriori algorithm is more versatile than the Tree Projection method. Last but not least, implemented techniques of them are different: The Apriori algorithm employs a candidate generation approach, whereas the Tree Projection method traverses the data set and generates frequent itemsets using a tree-based approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnVm8wYIRjaV"
   },
   "source": [
    "# 3. Churn analysis\n",
    "\n",
    "In this section, you will use frequent itemset mining technique to analyze `churn` dataset (for any purposes). \n",
    "\n",
    "* Remember this dataset is not represented as a transactional database, first thing that you have to do is transforming it into a flat file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account Length</th>\n",
       "      <th>Area Code</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Int&amp;#39;l Plan</th>\n",
       "      <th>VMail Plan</th>\n",
       "      <th>VMail Message</th>\n",
       "      <th>Day Mins</th>\n",
       "      <th>Day Calls</th>\n",
       "      <th>Day Charge</th>\n",
       "      <th>...</th>\n",
       "      <th>Eve Calls</th>\n",
       "      <th>Eve Charge</th>\n",
       "      <th>Night Mins</th>\n",
       "      <th>Night Calls</th>\n",
       "      <th>Night Charge</th>\n",
       "      <th>Intl Mins</th>\n",
       "      <th>Intl Calls</th>\n",
       "      <th>Intl Charge</th>\n",
       "      <th>CustServ Calls</th>\n",
       "      <th>Churn?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>382-4657</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>371-7191</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>358-1921</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>375-9999</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>330-6626</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>AZ</td>\n",
       "      <td>192</td>\n",
       "      <td>415</td>\n",
       "      <td>414-4276</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>36</td>\n",
       "      <td>156.2</td>\n",
       "      <td>77</td>\n",
       "      <td>26.55</td>\n",
       "      <td>...</td>\n",
       "      <td>126</td>\n",
       "      <td>18.32</td>\n",
       "      <td>279.1</td>\n",
       "      <td>83</td>\n",
       "      <td>12.56</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>WV</td>\n",
       "      <td>68</td>\n",
       "      <td>415</td>\n",
       "      <td>370-3271</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>231.1</td>\n",
       "      <td>57</td>\n",
       "      <td>39.29</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>13.04</td>\n",
       "      <td>191.3</td>\n",
       "      <td>123</td>\n",
       "      <td>8.61</td>\n",
       "      <td>9.6</td>\n",
       "      <td>4</td>\n",
       "      <td>2.59</td>\n",
       "      <td>3</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>RI</td>\n",
       "      <td>28</td>\n",
       "      <td>510</td>\n",
       "      <td>328-8230</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>180.8</td>\n",
       "      <td>109</td>\n",
       "      <td>30.74</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>24.55</td>\n",
       "      <td>191.9</td>\n",
       "      <td>91</td>\n",
       "      <td>8.64</td>\n",
       "      <td>14.1</td>\n",
       "      <td>6</td>\n",
       "      <td>3.81</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>CT</td>\n",
       "      <td>184</td>\n",
       "      <td>510</td>\n",
       "      <td>364-6381</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>213.8</td>\n",
       "      <td>105</td>\n",
       "      <td>36.35</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>13.57</td>\n",
       "      <td>139.2</td>\n",
       "      <td>137</td>\n",
       "      <td>6.26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>TN</td>\n",
       "      <td>74</td>\n",
       "      <td>415</td>\n",
       "      <td>400-4344</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>234.4</td>\n",
       "      <td>113</td>\n",
       "      <td>39.85</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>22.60</td>\n",
       "      <td>241.4</td>\n",
       "      <td>77</td>\n",
       "      <td>10.86</td>\n",
       "      <td>13.7</td>\n",
       "      <td>4</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3333 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     State  Account Length  Area Code     Phone Int&#39;l Plan VMail Plan  \\\n",
       "0       KS             128        415  382-4657             no        yes   \n",
       "1       OH             107        415  371-7191             no        yes   \n",
       "2       NJ             137        415  358-1921             no         no   \n",
       "3       OH              84        408  375-9999            yes         no   \n",
       "4       OK              75        415  330-6626            yes         no   \n",
       "...    ...             ...        ...       ...            ...        ...   \n",
       "3328    AZ             192        415  414-4276             no        yes   \n",
       "3329    WV              68        415  370-3271             no         no   \n",
       "3330    RI              28        510  328-8230             no         no   \n",
       "3331    CT             184        510  364-6381            yes         no   \n",
       "3332    TN              74        415  400-4344             no        yes   \n",
       "\n",
       "      VMail Message  Day Mins  Day Calls  Day Charge  ...  Eve Calls  \\\n",
       "0                25     265.1        110       45.07  ...         99   \n",
       "1                26     161.6        123       27.47  ...        103   \n",
       "2                 0     243.4        114       41.38  ...        110   \n",
       "3                 0     299.4         71       50.90  ...         88   \n",
       "4                 0     166.7        113       28.34  ...        122   \n",
       "...             ...       ...        ...         ...  ...        ...   \n",
       "3328             36     156.2         77       26.55  ...        126   \n",
       "3329              0     231.1         57       39.29  ...         55   \n",
       "3330              0     180.8        109       30.74  ...         58   \n",
       "3331              0     213.8        105       36.35  ...         84   \n",
       "3332             25     234.4        113       39.85  ...         82   \n",
       "\n",
       "      Eve Charge  Night Mins  Night Calls  Night Charge  Intl Mins  \\\n",
       "0          16.78       244.7           91         11.01       10.0   \n",
       "1          16.62       254.4          103         11.45       13.7   \n",
       "2          10.30       162.6          104          7.32       12.2   \n",
       "3           5.26       196.9           89          8.86        6.6   \n",
       "4          12.61       186.9          121          8.41       10.1   \n",
       "...          ...         ...          ...           ...        ...   \n",
       "3328       18.32       279.1           83         12.56        9.9   \n",
       "3329       13.04       191.3          123          8.61        9.6   \n",
       "3330       24.55       191.9           91          8.64       14.1   \n",
       "3331       13.57       139.2          137          6.26        5.0   \n",
       "3332       22.60       241.4           77         10.86       13.7   \n",
       "\n",
       "      Intl Calls  Intl Charge  CustServ Calls  Churn?  \n",
       "0              3         2.70               1  False.  \n",
       "1              3         3.70               1  False.  \n",
       "2              5         3.29               0  False.  \n",
       "3              7         1.78               2  False.  \n",
       "4              3         2.73               3  False.  \n",
       "...          ...          ...             ...     ...  \n",
       "3328           6         2.67               2  False.  \n",
       "3329           4         2.59               3  False.  \n",
       "3330           6         3.81               2  False.  \n",
       "3331          10         1.35               2  False.  \n",
       "3332           4         3.70               0  False.  \n",
       "\n",
       "[3333 rows x 21 columns]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn = []\n",
    "with open('churn.txt', 'r') as temp:\n",
    "    for line in temp:\n",
    "        if 'blob-code blob-code-inner js-file-line' in line:\n",
    "            start = line.find('>') + 1\n",
    "            end = line.rfind('<')\n",
    "            churn.append(line[start:end])\n",
    "with open('churn.csv', 'w') as temp:\n",
    "    temp.write('\\n'.join(churn))\n",
    "churn_df = pd.read_csv('churn.csv')\n",
    "churn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State              object\n",
      "Account Length      int64\n",
      "Area Code           int64\n",
      "Phone              object\n",
      "Int&#39;l Plan     object\n",
      "VMail Plan         object\n",
      "VMail Message       int64\n",
      "Day Mins          float64\n",
      "Day Calls           int64\n",
      "Day Charge        float64\n",
      "Eve Mins          float64\n",
      "Eve Calls           int64\n",
      "Eve Charge        float64\n",
      "Night Mins        float64\n",
      "Night Calls         int64\n",
      "Night Charge      float64\n",
      "Intl Mins         float64\n",
      "Intl Calls          int64\n",
      "Intl Charge       float64\n",
      "CustServ Calls      int64\n",
      "Churn?             object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('churn.csv')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData1(path):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    --------------------------\n",
    "        path: path of database D.\n",
    "         \n",
    "    --------------------------\n",
    "    Returns\n",
    "        data: a dictionary for representing database D\n",
    "                 - keys: transaction tids\n",
    "                 - values: itemsets.\n",
    "        s: support of distict items in D.\n",
    "    \"\"\"\n",
    "    data={}\n",
    "    s=defaultdict(lambda: 0)\n",
    "    with open(path, 'rt') as f:\n",
    "        tid=1;\n",
    "        header = f.readline()\n",
    "        columns = header[:-1].split(',') \n",
    "        for line in f:\n",
    "            line = line[:-1] \n",
    "            itemset = set(list(\"{}_{}\".format(col, value) for col, value in zip(columns, line.split(\",\"))))\n",
    "            for item in itemset:\n",
    "                s[item]+=1\n",
    "            data[tid]=itemset\n",
    "            tid+=1  \n",
    "    return data, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [['CustServ Calls_1'], ['Area Code_415'], ['VMail Plan_no'], ['VMail Message_0'], ['Churn?_False.'], ['Int&#39;l Plan_no']], 2: [['Churn?_False.', 'CustServ Calls_1'], ['CustServ Calls_1', 'Int&#39;l Plan_no'], ['Area Code_415', 'VMail Plan_no'], ['Area Code_415', 'VMail Message_0'], ['Area Code_415', 'Churn?_False.'], ['Area Code_415', 'Int&#39;l Plan_no'], ['VMail Message_0', 'VMail Plan_no'], ['Churn?_False.', 'VMail Plan_no'], ['Int&#39;l Plan_no', 'VMail Plan_no'], ['Churn?_False.', 'VMail Message_0'], ['Int&#39;l Plan_no', 'VMail Message_0'], ['Churn?_False.', 'Int&#39;l Plan_no']], 3: [['Area Code_415', 'VMail Message_0', 'VMail Plan_no'], ['Area Code_415', 'Int&#39;l Plan_no', 'VMail Plan_no'], ['Area Code_415', 'Int&#39;l Plan_no', 'VMail Message_0'], ['Area Code_415', 'Churn?_False.', 'Int&#39;l Plan_no'], ['Churn?_False.', 'VMail Message_0', 'VMail Plan_no'], ['Int&#39;l Plan_no', 'VMail Message_0', 'VMail Plan_no'], ['Churn?_False.', 'Int&#39;l Plan_no', 'VMail Plan_no'], ['Churn?_False.', 'Int&#39;l Plan_no', 'VMail Message_0']], 4: [['Area Code_415', 'Int&#39;l Plan_no', 'VMail Message_0', 'VMail Plan_no'], ['Churn?_False.', 'Int&#39;l Plan_no', 'VMail Message_0', 'VMail Plan_no']]}\n"
     ]
    }
   ],
   "source": [
    "def joinset(a, b):\n",
    "    '''\n",
    "    Parameters\n",
    "    -------------------\n",
    "        2 itemsets a and b (of course they are at same branch in search space)\n",
    "    -------------------\n",
    "    return\n",
    "        ret: itemset generated by joining a and b\n",
    "    '''\n",
    "    # TODO (hint: this function will be called in generateSearchSpace method.):\n",
    "    ret = list(set(a + b))\n",
    "    ret = sorted(ret)  \n",
    "    return ret\n",
    "\n",
    "class TP:\n",
    "    def __init__(self, data=None, s=None, minSup=None):\n",
    "        self.data = data\n",
    "        self.s = {}\n",
    "        for key, support in sorted(s.items(), key=lambda item: item[1]):\n",
    "            self.s[key] = support\n",
    "        # TODO: why should we do this, answer it at the markdown below?\n",
    "        self.minSup = minSup\n",
    "        self.L = {}  # Store frequent itemsets mined from database\n",
    "        self.runAlgorithm()\n",
    "        \n",
    "    def initialize(self):\n",
    "        \"\"\"\n",
    "        Initialize search space at first step\n",
    "        --------------------------------------\n",
    "        We represent our search space in a tree structure\n",
    "        \"\"\"\n",
    "        tree = {}\n",
    "        search_space = {}\n",
    "        for item, support in self.s.items():\n",
    "            search_space[item] = {}\n",
    "            search_space[item]['itemset'] = [item]\n",
    "            ''' \n",
    "            python set does not remain elements order\n",
    "            so we use a list to extend it easily when create new itemset \n",
    "            but why we store itemset in data by a python set???? '''\n",
    "            # TODO: study about python set and its advantages,\n",
    "            # answer at the markdown below.\n",
    "            search_space[item]['pruned'] = False\n",
    "            # TODO:\n",
    "            # After finish implementing the algorithm tell me why should you use this\n",
    "            # instead of delete item directly from search_space and tree.\n",
    "            search_space[item]['support'] = support\n",
    "            tree[item] = {}\n",
    "            '''\n",
    "            Why should i store an additional tree (here it called tree)? \n",
    "            Answer: This really help in next steps.\n",
    "            Remember that there is always a big gap from theory to practicality\n",
    "            and implementing this algorithm in python is not as simple as you think.\n",
    "            '''\n",
    "        return tree, search_space\n",
    "    \n",
    "    def computeItemsetSupport(self, itemset):\n",
    "        '''Return support of itemset'''\n",
    "        support = 0\n",
    "        if isinstance(itemset, int):\n",
    "            itemset = {itemset}\n",
    "        else:\n",
    "            itemset = set(itemset)\n",
    "        for transaction in self.data.values():\n",
    "            if itemset.issubset(transaction):\n",
    "                support += 1\n",
    "        return support\n",
    "    \n",
    "    def get_sub_tree(self, k, tree, search_space, itter_node):\n",
    "        if k == 0:\n",
    "            return search_space[itter_node]['support']\n",
    "        subtree = search_space[itter_node]\n",
    "        for node in subtree.keys():\n",
    "            k-=1\n",
    "            self.get_sub_tree(k,tree,search_space,node)\n",
    "\n",
    "    def prune(self, k, tree, search_space):\n",
    "        '''\n",
    "        In this method we will find out which itemset in current search space is frequent\n",
    "        itemset then add it to L[k]. In addition, we prune those are not frequent itemsets.\n",
    "        '''\n",
    "        if self.L.get(k) is None: self.L[k] = []\n",
    "        # TODO\n",
    "        itemset_support = []\n",
    "        for it_set in search_space.keys():\n",
    "            support = self.computeItemsetSupport(it_set)\n",
    "            itemset_support.append(support)\n",
    "        for itemset, properties in search_space.items():  \n",
    "            if properties['pruned']:\n",
    "                continue\n",
    "            support = self.computeItemsetSupport(search_space[itemset]['itemset'])\n",
    "            if support < self.minSup:\n",
    "                search_space[itemset]['pruned'] = True\n",
    "            else:\n",
    "                frequent_itemset = list(properties['itemset'])\n",
    "                self.L[k].append(frequent_itemset)\n",
    "        \n",
    "    def generateSearchSpace(self, k, tree, search_space):\n",
    "        '''\n",
    "        Generate search space for exploring k+1 itemset. (Recursive function)\n",
    "        '''\n",
    "        items = list(tree.keys())\n",
    "        ''' print search_space.keys() you will understand  \n",
    "         why we need an additional tree, '''\n",
    "        l = len(items)\n",
    "        self.prune(k, tree, search_space)\n",
    "        if l == 0: return  # Stop condition\n",
    "        for i in range(l - 1):\n",
    "            sub_search_space = {}\n",
    "            sub_tree = {}\n",
    "            a = items[i]\n",
    "            if search_space[a]['pruned']: continue\n",
    "            for j in range(i + 1, l):\n",
    "                b = items[j]\n",
    "                search_space[a][b] = {}\n",
    "                tree[a][b] = {}\n",
    "                # You really need to understand what am i doing here before doing work below.\n",
    "                # TODO:\n",
    "                # First create newset using join set               \n",
    "                newset = tuple(sorted(joinset(list(search_space[a]['itemset']), list(search_space[b]['itemset']))))               \n",
    "                # Second add newset to search_space\n",
    "                if newset is not None:\n",
    "                    newset_support = self.computeItemsetSupport(newset)\n",
    "                    newset = tuple(newset)   \n",
    "                    if newset_support >= self.minSup:\n",
    "                        search_space[a][b]['itemset'] = list(newset)\n",
    "                        search_space[a][b]['pruned'] = False\n",
    "                        search_space[a][b]['support'] = newset_support\n",
    "                        search_space[newset] = {'itemset': newset, 'pruned': False, 'support': newset_support}\n",
    "                        sub_search_space[newset] = {'itemset': newset, 'pruned': False, 'support': newset_support}\n",
    "                        sub_tree[newset] = {}                \n",
    "            #  Generate search_space for k+1-itemset\n",
    "            self.generateSearchSpace(k + 1, sub_tree, sub_search_space)\n",
    "            \n",
    "    def runAlgorithm(self):\n",
    "        tree, search_space = self.initialize()  # generate search space for 1-itemset\n",
    "        self.generateSearchSpace(1, tree, search_space)\n",
    "        \n",
    "    def miningResults(self):\n",
    "        return self.L\n",
    "    # Read churn.csv\n",
    "    data1, s1 = readData1('churn.csv')\n",
    "    a1=TP(data=data1,s=s1, minSup=1000)\n",
    "    frequent_itemsets = a1.miningResults()\n",
    "    print(frequent_itemsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With Minup = 1000, I can realize that these result has Churn key:\n",
    "\n",
    "['Area Code_415', 'Churn?_False.', 'Int&#39;l Plan_no'], \n",
    "\n",
    "\n",
    "['Churn?_False.', 'VMail Message_0', 'VMail Plan_no'], \n",
    "\n",
    "\n",
    "['Int&#39;l Plan_no', 'VMail Message_0', 'VMail Plan_no'], \n",
    "\n",
    "\n",
    "['Churn?_False.', 'Int&#39;l Plan_no', 'VMail Plan_no'], \n",
    "\n",
    "\n",
    "['Churn?_False.', 'Int&#39;l Plan_no', 'VMail Message_0']], \n",
    "\n",
    "\n",
    "['Churn?_False.', 'Int&#39;l Plan_no', 'VMail Message_0', 'VMail Plan_no']]}\n",
    "\n",
    "- We can find out meaningful association law that :\n",
    "\n",
    "If 'Int&#39;l Plan is **No** and VMail Plan is **No** that Churn = **False**\n",
    "\n",
    "OR\n",
    "\n",
    "If 'Int&#39;l Plan is **No** and VMail Message is **No** that Churn = **False**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FzxGs7RRjaX"
   },
   "source": [
    "# 4 References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "doYH4biqR_N7"
   },
   "source": [
    "Feel free to send questions to my email address: ntthuhang0131@gmail.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Lab01 - Frequent itemset mining.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
